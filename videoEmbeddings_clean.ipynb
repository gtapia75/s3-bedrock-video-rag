{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"rFwwiNyNuBI4"},"outputs":[],"source":["# ============================================================\n","# Video RAG v1 (POC) — AWS S3 + Bedrock Titan (multimodal embeddings) + ChromaDB\n","# Optional: OpenAI Vision summaries of retrieved frames\n","#\n","# POC assumptions:\n","# - Only a few short videos (< 1 minute each)\n","# - You want to learn the workflow end-to-end\n","#\n","# COST CONTROLS BUILT IN:\n","# - Sample a frame every N seconds\n","# - Hard cap frames per video\n","# - Cache frames already embedded (avoid re-paying)\n","# ============================================================\n"]},{"cell_type":"code","source":["!pip install -q boto3 pillow chromadb openai opencv-python-headless\n"],"metadata":{"id":"RYosCbAA5xnk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import io\n","import json\n","import base64\n","import hashlib\n","from pathlib import Path\n","from typing import List, Dict, Optional, Tuple\n","\n","import boto3\n","from botocore.exceptions import ClientError, NoCredentialsError\n","\n","import cv2\n","from PIL import Image, ImageOps\n","import matplotlib.pyplot as plt\n","\n","import chromadb\n","from openai import OpenAI\n"],"metadata":{"id":"wLfsUvq25zLS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ⚠️ DO NOT commit these anywhere permanent\n","os.environ[\"AWS_ACCESS_KEY_ID\"] = \"<YOUR AWS ACCESS KEY>\"\n","os.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"<YOUR AWS SECRET KEY>\"\n","os.environ[\"AWS_DEFAULT_REGION\"] = \"us-east-1\"  # change if needed\n","import os, getpass\n","\n","os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")\n"],"metadata":{"id":"3x04LmBn6KUa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# -----------------------------\n","# S3\n","# -----------------------------\n","BUCKET = \"<YOUR S3 NAME>\"\n","VIDEO_PREFIX = \"\"        # e.g., \"poc/videos/\" or \"\" if root\n","VIDEO_EXTS = (\".mp4\", \".mov\", \".m4v\", \".avi\")\n","\n","LOCAL_VIDEO_DIR = \"data/videos\"\n","LOCAL_FRAME_DIR = \"data/frames\"\n","\n","# -----------------------------\n","# Bedrock\n","# -----------------------------\n","BEDROCK_REGION = os.environ.get(\"AWS_DEFAULT_REGION\", \"us-east-1\")\n","TITAN_MODEL_ID = \"amazon.titan-embed-image-v1\"\n","EMBED_DIM = 1024\n","\n","# -----------------------------\n","# Chroma\n","# -----------------------------\n","CHROMA_DIR = \"chroma_video_db\"\n","CHROMA_COLLECTION = \"video_frames\"\n","\n","# -----------------------------\n","# COST / SAFETY KNOBS\n","# -----------------------------\n","SAMPLE_EVERY_SEC = 1.0          # for <1min videos, 1 frame/sec is fine\n","MAX_FRAMES_PER_VIDEO = 80       # hard cap\n","MAX_FRAMES_TOTAL_RUN = 300      # safety switch across all videos\n","MAX_FRAME_SIDE = 768            # resize frames before embedding (faster + more reliable)\n","\n","# -----------------------------\n","# Optional OpenAI\n","# -----------------------------\n","OPENAI_VISION_MODEL = \"gpt-4.1-mini\"\n"],"metadata":{"id":"_MIQ3AqK51cu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_s3_client():\n","    return boto3.client(\"s3\")\n","\n","def list_video_keys(bucket: str, prefix: str, exts=VIDEO_EXTS, max_keys: Optional[int]=None) -> List[str]:\n","    s3 = get_s3_client()\n","    keys = []\n","    token = None\n","\n","    try:\n","        while True:\n","            kwargs = {\"Bucket\": bucket, \"Prefix\": prefix}\n","            if token:\n","                kwargs[\"ContinuationToken\"] = token\n","            resp = s3.list_objects_v2(**kwargs)\n","\n","            for obj in resp.get(\"Contents\", []):\n","                key = obj[\"Key\"]\n","                if key.lower().endswith(tuple(e.lower() for e in exts)):\n","                    keys.append(key)\n","                    if max_keys and len(keys) >= max_keys:\n","                        return keys\n","\n","            if resp.get(\"IsTruncated\"):\n","                token = resp.get(\"NextContinuationToken\")\n","            else:\n","                break\n","    except NoCredentialsError:\n","        raise RuntimeError(\"AWS credentials not found in this runtime.\")\n","    except ClientError as e:\n","        raise RuntimeError(f\"S3 list failed: {e}\")\n","\n","    return keys\n","\n","def download_s3_video(bucket: str, key: str, local_dir: str = LOCAL_VIDEO_DIR) -> str:\n","    s3 = get_s3_client()\n","    local_dir = Path(local_dir)\n","    local_dir.mkdir(parents=True, exist_ok=True)\n","\n","    local_path = local_dir / key\n","    local_path.parent.mkdir(parents=True, exist_ok=True)\n","\n","    try:\n","        s3.download_file(bucket, key, str(local_path))\n","    except ClientError as e:\n","        raise RuntimeError(f\"Download failed for {key}: {e}\")\n","\n","    return str(local_path)\n"],"metadata":{"id":"reS3f-0654zK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def safe_mkdir(path: str):\n","    Path(path).mkdir(parents=True, exist_ok=True)\n","\n","def extract_frames_opencv(\n","    video_path: str,\n","    out_dir: str,\n","    sample_every_sec: float = SAMPLE_EVERY_SEC,\n","    max_frames: int = MAX_FRAMES_PER_VIDEO\n",") -> List[Dict]:\n","    \"\"\"\n","    Extract frames every N seconds and save as JPEG.\n","    Returns records: {frame_path, timestamp_sec, frame_index}\n","    \"\"\"\n","    safe_mkdir(out_dir)\n","\n","    cap = cv2.VideoCapture(video_path)\n","    if not cap.isOpened():\n","        raise RuntimeError(f\"Could not open video: {video_path}\")\n","\n","    fps = cap.get(cv2.CAP_PROP_FPS) or 30.0\n","    step = max(int(fps * sample_every_sec), 1)\n","\n","    records = []\n","    frame_idx = 0\n","    saved = 0\n","\n","    while True:\n","        ret, frame = cap.read()\n","        if not ret:\n","            break\n","\n","        if frame_idx % step == 0:\n","            timestamp_sec = frame_idx / fps\n","            out_path = Path(out_dir) / f\"frame_{saved:06d}_{int(timestamp_sec*1000)}ms.jpg\"\n","\n","            rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n","            img = Image.fromarray(rgb)\n","            img.save(out_path, format=\"JPEG\", quality=90, optimize=True)\n","\n","            records.append({\n","                \"frame_path\": str(out_path),\n","                \"timestamp_sec\": float(timestamp_sec),\n","                \"frame_index\": int(frame_idx),\n","            })\n","\n","            saved += 1\n","            if saved >= max_frames:\n","                break\n","\n","        frame_idx += 1\n","\n","    cap.release()\n","    return records\n"],"metadata":{"id":"kWlcq3jR55aU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def normalize_image_to_jpeg_bytes(image_path: str, max_side: int = MAX_FRAME_SIDE, quality: int = 90) -> bytes:\n","    \"\"\"\n","    Converts to clean RGB JPEG bytes, fixes orientation, resizes if large.\n","    Helps prevent Bedrock \"Unable to process provided image\".\n","    \"\"\"\n","    with Image.open(image_path) as img:\n","        img = ImageOps.exif_transpose(img)\n","        if img.mode != \"RGB\":\n","            img = img.convert(\"RGB\")\n","\n","        w, h = img.size\n","        scale = max(w, h) / max_side\n","        if scale > 1:\n","            img = img.resize((int(w/scale), int(h/scale)))\n","\n","        buf = io.BytesIO()\n","        img.save(buf, format=\"JPEG\", quality=quality, optimize=True)\n","        return buf.getvalue()\n"],"metadata":{"id":"-i0tWlfi57Au"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_bedrock_runtime(region_name: str = BEDROCK_REGION):\n","    return boto3.client(\"bedrock-runtime\", region_name=region_name)\n","\n","def titan_embed_image_bytes(jpeg_bytes: bytes, output_dim: int = EMBED_DIM) -> List[float]:\n","    br = get_bedrock_runtime()\n","    body = json.dumps({\n","        \"inputImage\": base64.b64encode(jpeg_bytes).decode(\"utf-8\"),\n","        \"embeddingConfig\": {\"outputEmbeddingLength\": output_dim}\n","    })\n","    resp = br.invoke_model(\n","        modelId=TITAN_MODEL_ID,\n","        body=body,\n","        accept=\"application/json\",\n","        contentType=\"application/json\"\n","    )\n","    data = json.loads(resp[\"body\"].read())\n","    if data.get(\"message\"):\n","        raise RuntimeError(data[\"message\"])\n","    return data[\"embedding\"]\n","\n","def titan_embed_image_safe(image_path: str, output_dim: int = EMBED_DIM) -> List[float]:\n","    jpeg = normalize_image_to_jpeg_bytes(image_path)\n","    return titan_embed_image_bytes(jpeg, output_dim=output_dim)\n","\n","def titan_embed_text(query: str, output_dim: int = EMBED_DIM) -> List[float]:\n","    br = get_bedrock_runtime()\n","    body = json.dumps({\n","        \"inputText\": query,\n","        \"embeddingConfig\": {\"outputEmbeddingLength\": output_dim}\n","    })\n","    resp = br.invoke_model(\n","        modelId=TITAN_MODEL_ID,\n","        body=body,\n","        accept=\"application/json\",\n","        contentType=\"application/json\"\n","    )\n","    data = json.loads(resp[\"body\"].read())\n","    if data.get(\"message\"):\n","        raise RuntimeError(data[\"message\"])\n","    return data[\"embedding\"]\n"],"metadata":{"id":"DWOG3arG584g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_chroma_collection(persist_dir: str = CHROMA_DIR, collection_name: str = CHROMA_COLLECTION):\n","    client = chromadb.PersistentClient(path=persist_dir)\n","    return client.get_or_create_collection(name=collection_name)\n","\n","def make_frame_id(video_key: str, timestamp_sec: float) -> str:\n","    raw = f\"{video_key}|{int(timestamp_sec*1000)}\"\n","    return hashlib.sha1(raw.encode(\"utf-8\")).hexdigest()\n","\n","def already_indexed(collection, frame_id: str) -> bool:\n","    try:\n","        got = collection.get(ids=[frame_id], include=[])\n","        return len(got[\"ids\"]) > 0\n","    except Exception:\n","        return False\n"],"metadata":{"id":"zvGBEr5P5_pc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def index_video_to_chroma(\n","    collection,\n","    bucket: str,\n","    video_key: str,\n","    sample_every_sec: float = SAMPLE_EVERY_SEC,\n","    max_frames_per_video: int = MAX_FRAMES_PER_VIDEO,\n","    max_frames_total_run: int = MAX_FRAMES_TOTAL_RUN,\n","    upsert_batch_size: int = 16\n",") -> Dict:\n","    \"\"\"\n","    Index one video into Chroma:\n","      - download video locally\n","      - extract frames every N seconds\n","      - embed frames with Titan\n","      - upsert into Chroma with timestamp metadata\n","    \"\"\"\n","    # Download\n","    video_path = download_s3_video(bucket, video_key, local_dir=LOCAL_VIDEO_DIR)\n","\n","    # Extract frames\n","    frame_dir = str(Path(LOCAL_FRAME_DIR) / video_key)\n","    frames = extract_frames_opencv(\n","        video_path=video_path,\n","        out_dir=frame_dir,\n","        sample_every_sec=sample_every_sec,\n","        max_frames=max_frames_per_video\n","    )\n","\n","    stats = {\n","        \"video_key\": video_key,\n","        \"video_path\": video_path,\n","        \"frames_extracted\": len(frames),\n","        \"frames_indexed\": 0,\n","        \"skipped_cached\": 0,\n","        \"failed\": []\n","    }\n","\n","    ids, embs, metas, docs = [], [], [], []\n","    remaining = max_frames_total_run  # global safety cap for this run\n","\n","    for f in frames:\n","        if remaining <= 0:\n","            break\n","\n","        frame_id = make_frame_id(video_key, f[\"timestamp_sec\"])\n","        if already_indexed(collection, frame_id):\n","            stats[\"skipped_cached\"] += 1\n","            continue\n","\n","        try:\n","            emb = titan_embed_image_safe(f[\"frame_path\"], output_dim=EMBED_DIM)\n","            ids.append(frame_id)\n","            embs.append(emb)\n","            metas.append({\n","                \"video_bucket\": bucket,\n","                \"video_key\": video_key,\n","                \"timestamp_sec\": f[\"timestamp_sec\"],\n","                \"frame_index\": f[\"frame_index\"],\n","                \"frame_path\": f[\"frame_path\"],\n","            })\n","            docs.append(\"\")\n","\n","            stats[\"frames_indexed\"] += 1\n","            remaining -= 1\n","\n","        except Exception as e:\n","            stats[\"failed\"].append({\n","                \"frame_path\": f[\"frame_path\"],\n","                \"timestamp_sec\": f[\"timestamp_sec\"],\n","                \"error\": str(e)\n","            })\n","\n","        if len(ids) >= upsert_batch_size:\n","            collection.upsert(ids=ids, embeddings=embs, metadatas=metas, documents=docs)\n","            ids, embs, metas, docs = [], [], [], []\n","\n","    if ids:\n","        collection.upsert(ids=ids, embeddings=embs, metadatas=metas, documents=docs)\n","\n","    return stats\n"],"metadata":{"id":"P150BHS46BII"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def query_video_frames(collection, text_query: str, k: int = 8) -> List[Dict]:\n","    q = titan_embed_text(text_query, output_dim=EMBED_DIM)\n","    res = collection.query(\n","        query_embeddings=[q],\n","        n_results=k,\n","        include=[\"metadatas\", \"distances\"]\n","    )\n","    out = []\n","    for _id, dist, meta in zip(res[\"ids\"][0], res[\"distances\"][0], res[\"metadatas\"][0]):\n","        out.append({\"id\": _id, \"distance\": dist, \"metadata\": meta})\n","    return out\n","\n","def show_frame_hits(hits: List[Dict], n: int = 6):\n","    for h in hits[:n]:\n","        meta = h[\"metadata\"]\n","        p = meta.get(\"frame_path\")\n","        if not p or not Path(p).exists():\n","            continue\n","\n","        img = Image.open(p)\n","        plt.figure()\n","        plt.imshow(img)\n","        plt.axis(\"off\")\n","        plt.title(f\"{Path(p).name} | dist={h['distance']:.4f}\\n{meta.get('video_key')} @ {meta.get('timestamp_sec'):.2f}s\")\n","        plt.show()\n"],"metadata":{"id":"P8Ms-NTP6CZe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def image_to_b64(path: str) -> str:\n","    return base64.b64encode(Path(path).read_bytes()).decode(\"utf-8\")\n","\n","def summarize_frames_with_openai(text_query: str, hits: List[Dict], n_images: int = 4, model: str = OPENAI_VISION_MODEL) -> str:\n","    client = OpenAI()\n","\n","    selected = hits[:n_images]\n","    index_lines = []\n","    content = [{\"type\": \"text\", \"text\": \"\"}]\n","\n","    actual = []\n","    for i, h in enumerate(selected, start=1):\n","        meta = h[\"metadata\"]\n","        p = meta.get(\"frame_path\")\n","        if not p or not Path(p).exists():\n","            continue\n","        label = f\"S{i}\"\n","        index_lines.append(f\"{label}: {meta.get('video_key')} @ {meta.get('timestamp_sec'):.2f}s | dist={h['distance']:.4f}\")\n","        actual.append((label, p))\n","\n","    for label, p in actual:\n","        content.append({\n","            \"type\": \"image_url\",\n","            \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image_to_b64(p)}\"}\n","        })\n","\n","    prompt = (\n","        f\"User query: {text_query}\\n\\n\"\n","        \"Retrieved video frames index:\\n\" + \"\\n\".join(index_lines) + \"\\n\\n\"\n","        \"Instructions:\\n\"\n","        \"1) For each frame S1..Sn, describe what you see.\\n\"\n","        \"2) Explain briefly why it matches the query.\\n\"\n","        \"3) Provide a short overall summary.\\n\"\n","        \"CRITICAL: Reference frames using S1, S2, ... explicitly.\"\n","    )\n","    content[0][\"text\"] = prompt\n","\n","    resp = client.chat.completions.create(\n","        model=model,\n","        messages=[\n","            {\"role\": \"system\", \"content\": \"You are a concise video frame analyst.\"},\n","            {\"role\": \"user\", \"content\": content}\n","        ],\n","        temperature=0.2\n","    )\n","    return resp.choices[0].message.content\n"],"metadata":{"id":"Lw4PAGjC6EVF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["video_keys = list_video_keys(BUCKET, VIDEO_PREFIX, max_keys=3)\n","video_keys\n"],"metadata":{"id":"MifYE9XU8miT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["collection = get_chroma_collection()\n","\n","stats_all = []\n","for vk in video_keys:\n","    stats = index_video_to_chroma(collection, BUCKET, vk)\n","    stats_all.append(stats)\n","    print(json.dumps(stats, indent=2))\n","\n","print(\"Chroma count:\", collection.count())\n","\n"],"metadata":{"id":"wtOPOtG18qz0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["hits = query_video_frames(collection, \"T-Shirt\", k=8)\n","show_frame_hits(hits, n=6)\n"],"metadata":{"id":"7xGr941J86WS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(summarize_frames_with_openai(\"T-Shirt\", hits, n_images=4))\n"],"metadata":{"id":"wBAaGWBK9b6w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"qknABBBM9qUT"},"execution_count":null,"outputs":[]}]}